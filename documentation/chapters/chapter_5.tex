%!TEX root = ../ausarbeitung.tex
\section{Implementation}
\label{sec_implementation}

\subsection{Contour Detection}
\subsection{Template Matching}
To provide the algorithm an imagination of how the shapes which it is supposed to find look like, it is necessary to give it a sample shape to be geared on.
A possibility for that is using a template matching algorithm.
OpenCV provides this functionality, so the only thing to do was to define a comparison function.
By testing it turned out that CCOEFF gave the best results.
As templates cropped images from the insect library were used like in figure ???.
The result of that openCV algorithm was a list of all sub-images with their corresponding match values describing how good they match the template.
The part of the image where we took the template from, of course always had a value of 1, which is the best possible value.
All other values are beween -1 and 1, where a higher value means, that it matches the template better.
The next step is to set a threshold, defining from which value on sub-images are taken as matching.
A threshold of 0.41 worked best for us to avoid too many false posivies and true negatives.

Using this algorithm a result like in figure ??? is generated.

As you can see there are mostly multiple sub-images close to a match that are recognized as a match.
To group such corresponding matches together to one match, an overlay threshold of 30% was defined to tell the algorithm when two frames are put together.
The same image as in fugure ??? now with frame grouping in figure ???

In figure ??? you can see the results with the given algorithms so far.
As you can see there are many false positives left, which have to be discarded.
This is done by a second comparison using Histogram of Oriented Gradients.
If the matching value is below 0.95, the result is discarded.
Another problem is dirt and other unexpected noise on the image, that sometimes matches the template pretty well as a false positive.
To get rid of those results, the histogram of the whole image is generated to get the background color.
All matches now have to have an average color that has a certain difference to the background color to be taken as a match.
A final result can be seen in figure ???.

\subsection{Automated Template Extraction}
Until this point, the templated were provided manually by cropping images. 
Since the annotation has to run fully automated, the template extraction also has to be done by the algorithm.
The Edge Detection algorithm is reused here to provide a list of potential templates.
This list is still full of false positives that have to be discarded.
Setting a maximum value for the ratio can help finding most of them and also .......
\subsection{Annotations}
The simplest annotation is just an RDF-triple locating a bug on an image and describing it as Organism. 
The definition for an Organism and all properties we use to describe are part of the Darwin Core \footnote{http://rs.tdwg.org/dwc/} Standard of describing living organisms.

We can extract further information from a CSV file that was provided by the Deutsches Naturkundemuseum.
It contains a general overview of all species in a photograph. 
This includes dates and information about the family.

Whenever a new bug is found, it is added to the collection of bugs that will be written as RDF file at the end.
It is possible to annotate every bug with additional, specific properties (apart from those that apply to every insect in the box).

Such information can be found in QR codes as described in the next section.

\subsubsection{QR Code Analysis}

\subsection{Integrating Benchmarking}
Due to the availability of each algorithm as single step in the pipeline, it was easy to execute them in the exact same environment with the exact same parameters. 
Different from the usual pipeline, the step of selecting the examples was automated and the step of writing out RDF files was replaced by analyzing the discovered bugs.

To have a reliable set of data (a ``gold standard''), we created annotations for some photos manually. 
The photos were mainly taken randomly. 
In addition, we chose some photos which we found hard to analyze (due to transparent wings, difficult shapes or different sizes).

The actual gold standard was not a set of RDF files but a collections of comma-separated values. 
These CSV files were easier to create (with a helping tool we wrote to manually annotate the bugs) and easier to analyze than RDF documents with same contents.
The actual results, their effect on our process and how we could optimize the benchmarking process will be discussed in chapter \ref{sec_conclusion}.