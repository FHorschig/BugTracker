%!TEX root = ../ausarbeitung.tex
\section{Implementation}
\label{sec_implementation}

We implemented BugTracker as commandline-based Python tool.
It takes an image as input, and produces an RDF file with annotations of the found insects.
Template

\subsection{Contour Detection}
As a basic approach, we use Contour Detection to find insects in a given image.
The input image converted to gray-scale is used to detect edges as mentioned in Section \ref{sec_concepts}.
We use an adaptive threshold to create a binary image, which is then transformed by a morphological operation from OpenCV, in order to close gaps in areas of interest.
On this transformed binary image, an OpenCV contour detection function is applied, which groups connected edges into one contour.
Those contours are a first approach on finding something on an image.
However, the threshold and edge detection algorithm can not possibly know, what we are looking for.
The found contours can be anything that appears to stand out from the background, not only insects.
This method is a good approach to just find anything on the image, but not precise enough for our needs.


\subsection{Template Matching}

\subsection{Automated Template Extraction}


\subsection{Annotations}
The simplest annotation is just an RDF-triple locating a bug on an image and describing it as Organism. 
The definition for an Organism and all properties we use to describe are part of the Darwin Core \footnote{http://rs.tdwg.org/dwc/} Standard of describing living organisms.

We can extract further information from a CSV file that was provided by the Natural History Museum of Berlin.
It contains a general overview of all species in a photograph. 
This includes dates and information about the family.

Whenever a new bug is found, it is added to the collection of bugs that will be written as RDF file at the end.
It is possible to annotate every bug with additional, specific properties (apart from those that apply to every insect in the box).

Such information can be found in QR codes as described in the next section.

\subsubsection{QR Code Analysis}

\subsection{Integrating Benchmarking}
Due to the availability of each algorithm as single step in the pipeline, it was easy to execute them in the exact same environment with the exact same parameters. 
Different from the usual pipeline, the step of selecting the examples was automated and the step of writing out RDF files was replaced by analyzing the discovered bugs.

To have a reliable set of data (a ``gold standard''), we created annotations for some photos manually. 
The photos were mainly taken randomly. 
In addition, we chose some photos which we found hard to analyze (due to transparent wings, difficult shapes or different sizes).

The actual gold standard was not a set of RDF files but a collections of comma-separated values. 
These CSV files were easier to create (with a helping tool we wrote to manually annotate the bugs) and easier to analyze than RDF documents with same contents.
The actual results, their effect on our process and how we could optimize the benchmarking process will be discussed in chapter \ref{sec_conclusion}.